{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "537dc3cc",
   "metadata": {},
   "source": [
    "# SARIMA(X) Model\n",
    "\n",
    "#### Implementation of a SARIMAX/SARIMA (extension of ARIMA) model\n",
    "\n",
    "Links:\n",
    "- [SARIMAX Documentation](https://www.statsmodels.org/devel/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html)\n",
    "- [A Gentle Introduction to SARIMA for Time Series Forecasting in Python](https://machinelearningmastery.com/sarima-for-time-series-forecasting-in-python/)\n",
    "- [How to Grid Search SARIMA Hyperparameters for Time Series Forecasting in Python](https://machinelearningmastery.com/how-to-grid-search-sarima-model-hyperparameters-for-time-series-forecasting-in-python/)\n",
    "- [Complete Guide to SARIMAX in Python for Time Series Modeling](https://analyticsindiamag.com/complete-guide-to-sarimax-in-python-for-time-series-modeling/)\n",
    "- [Implementation of Time Series Forecasting Methods (SARIMA, SARIMAX, and Prophet)](https://medium.com/@shawanugya12/implementation-of-time-series-forecasting-methods-sarima-sarimax-and-prophet-ff8407b25aaa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc2fbc7",
   "metadata": {},
   "source": [
    "Import necessary modules and define helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dbe14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from datetime import datetime, time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pmdarima as pm\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "load_dotenv()\n",
    "DATASET_PATH = os.environ.get(\"DATASET_PATH\")\n",
    "\n",
    "\n",
    "def is_stationary(time_series: pd.Series, sig_level: float = 0.01) -> bool:\n",
    "    \"\"\"\n",
    "    Tests whether the given time series is stationary at the given significance\n",
    "    threshold using the ADF unit root test.\n",
    "\n",
    "    Parameters:\n",
    "        time_series: time series to test stationarity\n",
    "        sig_level: significance level to use for the test. defaults to 0.05\n",
    "\n",
    "    Returns:\n",
    "        (bool): True if the time series is stationary, False otherwise\n",
    "    \"\"\"\n",
    "    results = adfuller(time_series.values)\n",
    "    p_value = results[1]\n",
    "\n",
    "    return p_value < sig_level\n",
    "\n",
    "\n",
    "def calc_d(time_series: pd.Series, iter: int = 5) -> int:\n",
    "    \"\"\"\n",
    "    Calculates the value of the parameter d (order of differencing) for an\n",
    "    ARIMA model.\n",
    "\n",
    "    Parameters:\n",
    "        time_series: time series to calculate d for\n",
    "        iter: how many times to difference the time series, defaults to 5\n",
    "\n",
    "    Returns:\n",
    "        (int): optimal order of differencing\n",
    "    \"\"\"\n",
    "    differences = [(time_series, np.std(time_series), 0)]\n",
    "    # optimal order of differencing given by the (stationary) time series with\n",
    "    # the smallest standard deviation\n",
    "\n",
    "    # repeatedly difference the time series and store each time series, order\n",
    "    # and standard deviation in the list\n",
    "    df_diff = time_series.copy()\n",
    "    for order in range(1, iter+1):\n",
    "        # difference the previous time series and store it in list\n",
    "        df_diff = df_diff.diff().dropna()\n",
    "        differences.append((df_diff, np.std(df_diff), order))\n",
    "\n",
    "    # sort list by ascending standard deviation\n",
    "    sorted(differences, key=lambda x: x[1])\n",
    "\n",
    "    # find first time series in list that is stationary\n",
    "    for difference, _, order in differences:\n",
    "        if is_stationary(difference):  # optimal order of differencing found\n",
    "            d = order\n",
    "            break\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "def calc_p(time_series: pd.Series) -> int:\n",
    "    \"\"\"\n",
    "    Calculates the value of the parameter p (order of AR term) for an ARIMA\n",
    "    model.\n",
    "\n",
    "    Parameters:\n",
    "        time_series: time series to calculate p for\n",
    "    \"\"\"\n",
    "    # get values and confidence intervals from PACF plot\n",
    "    nlags = min(int(10*np.log10(time_series.size)), time_series.size//2 - 1)\n",
    "    values, conf_int = pacf(time_series, alpha=0.05, nlags=nlags)\n",
    "    # trim first value\n",
    "    values = values[1:]\n",
    "    conf_int = conf_int[1:]\n",
    "\n",
    "    # confidence interval width is constant for all PACFs\n",
    "    conf_int_width = (conf_int[0][1] - conf_int[0][0]) / 2\n",
    "\n",
    "    p = 0\n",
    "    for value in values:\n",
    "        if abs(value) >= conf_int_width:\n",
    "            # value outside critical region\n",
    "            p += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "def calc_q(time_series: pd.Series) -> int:\n",
    "    \"\"\"\n",
    "    Calculates the value of the parameter q (order of MA term) for an ARIMA\n",
    "    model.\n",
    "\n",
    "    Parameters:\n",
    "        time_series: time series to calculate q for\n",
    "    \"\"\"\n",
    "    # get values and confidence intervals from ACF plot\n",
    "    nlags = min(int(10*np.log10(time_series.size)), time_series.size//2 - 1)\n",
    "    values, conf_int = acf(time_series, alpha=0.05, nlags=nlags, fft=True)\n",
    "    # trim first value\n",
    "    values = values[1:]\n",
    "    conf_int = conf_int[1:]\n",
    "\n",
    "    q = 0\n",
    "    for i, value in enumerate(values):\n",
    "        if abs(value) >= abs(conf_int[i][0] - value):\n",
    "            # value is outside critical region\n",
    "            q += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f24287",
   "metadata": {},
   "source": [
    "Data preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d5a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_excel(DATASET_PATH + \"Conversion by Day.xlsx\")\n",
    "\n",
    "dimension_col = int(input(\"Column number of dimension variable: \"))\n",
    "response_col = int(input(\"Column number of response variable: \"))\n",
    "\n",
    "df = df_main.loc[df_main.iloc[:, 0] == \"NSW\"]\n",
    "\n",
    "# get the list of categories (possible values) for the selected dimension\n",
    "categories = df_main[df_main.columns[dimension_col]].tolist()\n",
    "categories = sorted(list(set(categories)))  # remove duplicates and sort alphabetically\n",
    "# store response variable as a string\n",
    "response = df_main.columns[response_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3118c91f",
   "metadata": {},
   "source": [
    "Determine ARIMA parameters (p, d, q):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c270d77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# find p, d, q in ARIMA model\n",
    "d = calc_d(df[response])\n",
    "\n",
    "df_diff = df[response].copy()\n",
    "for _ in range(d):\n",
    "    df_diff = df_diff.diff().dropna()\n",
    "\n",
    "p = calc_p(df_diff)\n",
    "q = calc_q(df_diff)\n",
    "print(f\"ARIMA parameters: {p, d, q}\")\n",
    "\n",
    "# split data into training vs. test dataset\n",
    "train, test = pm.model_selection.train_test_split(df[response], train_size=df.shape[0]-30)\n",
    "\n",
    "# grid search to find the optimal parameters\n",
    "model = pm.auto_arima(\n",
    "    train, start_p=0, d=d, start_q=0, max_p=p, max_d=d, max_q=q,\n",
    "    start_P=0, D=0, start_Q=0, max_P=3, max_D=3, max_Q=3,\n",
    "    m=12, seasonal=True\n",
    ")\n",
    "\n",
    "prediction, ci = model.predict(n_periods=test.shape[0], return_conf_int=True, dynamic=False)\n",
    "\n",
    "# plot ARIMA model against original dataset\n",
    "x_axis = np.arange(train.shape[0] + prediction.shape[0])\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (9, 6)\n",
    "plt.plot(x_axis[:train.shape[0]], train, alpha=0.75)\n",
    "plt.plot(x_axis[train.shape[0]:], prediction, alpha=0.75)\n",
    "plt.scatter(x_axis[train.shape[0]:], test, alpha=0.4, marker='x')\n",
    "plt.fill_between(x_axis[-prediction.shape[0]:], ci[:, 0], ci[:, 1], alpha=0.1, color='b')\n",
    "plt.title('Actual test samples vs. forecasts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f2d512",
   "metadata": {},
   "source": [
    "Output outliers as a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a8571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outliers = []\n",
    "for i in range(len(test)):\n",
    "    if not (ci[i][0] <= test.tolist()[i] <= ci[i][1]):  # outlier\n",
    "        outliers.append(train.shape[0] + i)\n",
    "\n",
    "df.iloc[outliers, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99be0f7a",
   "metadata": {},
   "source": [
    "All the categories (states) at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d2aa6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_main = pd.read_excel(DATASET_PATH + \"Conversion by Day.xlsx\")\n",
    "\n",
    "dimension_col = int(input(\"Column number of dimension variable: \"))\n",
    "response_col = int(input(\"Column number of response variable: \"))\n",
    "\n",
    "# get the list of categories (possible values) for the selected dimension\n",
    "categories = df_main[df_main.columns[dimension_col]].tolist()\n",
    "categories = sorted(list(set(categories)))  # remove duplicates and sort alphabetically\n",
    "# store response variable as a string\n",
    "response = df_main.columns[response_col]\n",
    "\n",
    "anomaly_dfs = []\n",
    "\n",
    "for category in categories:\n",
    "    df = df_main.loc[df_main.iloc[:, 0] == category]\n",
    "    \n",
    "    # find p, d, q in ARIMA model\n",
    "    d = calc_d(df[response])\n",
    "\n",
    "    # use the optimally differenced time series to calculate p and q\n",
    "    df_diff = df[response].copy()\n",
    "    for _ in range(d):\n",
    "        df_diff = df_diff.diff().dropna()\n",
    "\n",
    "    p = calc_p(df_diff)\n",
    "    q = calc_q(df_diff)\n",
    "    \n",
    "    # get the number of days that have passed since the first day of the last month;\n",
    "    # this will be the size of the test dataset\n",
    "    last_month = datetime.now() - pd.DateOffset(months=1)\n",
    "    last_month = datetime(last_month.year, last_month.month, 1)  # round to first day of month\n",
    "    days = (datetime.now() - last_month).days  # number of days to include in the test dataset\n",
    "    \n",
    "    train, test = pm.model_selection.train_test_split(df[response], train_size=df.shape[0]-days)\n",
    "    \n",
    "    # starting p, d, q parameters will be 2 less than the calculated parameters\n",
    "    start_p = 0 if (p - 2 < 0) else (p - 2)\n",
    "    start_d = 0 if (d - 2 < 0) else (d - 2)\n",
    "    start_q = 0 if (q - 2 < 0) else (q - 2)\n",
    "\n",
    "    # grid search to find the most optimal parameters\n",
    "    model = pm.auto_arima(\n",
    "        train, start_p=start_p, d=start_d, start_q=start_q, max_p=p, max_d=d, max_q=q,\n",
    "        start_P=0, D=0, start_Q=0, m=12, seasonal=True)\n",
    "\n",
    "    prediction, ci = model.predict(n_periods=test.shape[0], return_conf_int=True, dynamic=False)\n",
    "    x_axis = np.arange(train.shape[0] + prediction.shape[0])\n",
    "    \n",
    "    # find outliers by comparing values against confidence interval of forecast\n",
    "    anomaly_indices = []\n",
    "    for i in range(len(test)):\n",
    "        if not (ci[i][0] <= test.tolist()[i] <= ci[i][1]):  # outlier\n",
    "            anomaly_indices.append(train.shape[0] + i)\n",
    "    anomaly_df = df.iloc[anomaly_indices, :].copy()\n",
    "    anomaly_dfs.append(anomaly_df)\n",
    "    \n",
    "    print(category)\n",
    "    # plot original dataset, ARIMA model forecast, and test dataset points (as scatterplot)\n",
    "    plt.figure()\n",
    "    plt.plot(x_axis[:train.shape[0]], train, alpha=0.75)\n",
    "    plt.plot(x_axis[train.shape[0]:], prediction, alpha=0.75)\n",
    "    plt.scatter(x_axis[train.shape[0]:], test, alpha=0.4, marker='x')\n",
    "    plt.fill_between(x_axis[-prediction.shape[0]:], ci[:, 0], ci[:, 1], alpha=0.1, color='b')\n",
    "    plt.title('Actual test samples vs. forecasts')\n",
    "    plt.show()\n",
    "\n",
    "# collate all outliers into a dataframe and output it\n",
    "df_outliers = pd.concat(anomaly_dfs)\n",
    "display(df_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277936cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
