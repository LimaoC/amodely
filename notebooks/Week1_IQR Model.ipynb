{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IQR Model\n",
    "\n",
    "#### Using the IQR methodology to create an anomaly detection model\n",
    "\n",
    "This anomaly detection model detects historical and recent outliers using the method of interquartile range. A datapoint is considered an outlier if it lies outside the range $\\left(Q_1 - 1.5\\text{IQR}, Q_3 + 1.5\\text{IQR}\\right)$.\n",
    "\n",
    "Links:\n",
    "- [Why 1.5IQR is used for detecting outliers](https://math.stackexchange.com/questions/966331/why-john-tukey-set-1-5-iqr-to-detect-outliers-instead-of-1-or-2)\n",
    "- [Augmented Dickey-Fuller test](https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import all the necessary modules and set up the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from numpy import polyfit\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "load_dotenv()\n",
    "DATASET_PATH = os.environ.get(\"DATASET_PATH\")\n",
    "\n",
    "# main dataframe\n",
    "df = pd.read_excel(DATASET_PATH + \"Conversion by Day.xlsx\")\n",
    "\n",
    "# in this dataset the dimension is POLICY: Risk State, but this will work for any other single-dimension\n",
    "# dataset where the dimension is in the first column\n",
    "states = sorted(list(set(df[df.columns[0]].tolist())))  # convert to set then to list to remove duplicates\n",
    "\n",
    "# preview of dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter dataframe by state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = input(\"State: \")\n",
    "# select rows which match the input state\n",
    "df_new = df.loc[df.STATE_CODE == state][[\"QUOTE_DATE\", \"Net Closing Rate\"]]\n",
    "df_new.plot(x=\"QUOTE_DATE\", y=\"Net Closing Rate\", ylabel=\"Net Closing Rate\", legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the anomaly detection model to work, the data must be stationary (i.e. the mean and variance won't change over time). Some data preparation is required to remove the trends/seasonality in the data. First a polynomial of large degree is fit to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit polynomial model to data\n",
    "n = len(df_new[\"Net Closing Rate\"])  # number of data points\n",
    "\n",
    "X = [i % 365 for i in range(n)]\n",
    "y = df_new[\"Net Closing Rate\"].values\n",
    "degree = 10\n",
    "coefficients = polyfit(X, y, degree)\n",
    "\n",
    "# create curve\n",
    "polynomial = []\n",
    "for i in range(n):\n",
    "\tvalue = coefficients[-1]  # y-intercept\n",
    "\tfor d in range(degree):\n",
    "        # calculate the polynomial value at the point\n",
    "\t\tvalue += X[i]**(degree-d) * coefficients[d]\n",
    "\tpolynomial.append(value)\n",
    "    \n",
    "pyplot.plot(df_new[\"Net Closing Rate\"].values)\n",
    "pyplot.plot(polynomial);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then a new model is constructed, which takes the difference between the original value and the polynomial value at each data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonality adjustment\n",
    "difference = []\n",
    "for i in range(n):\n",
    "    value = y[i] - polynomial[i]\n",
    "    difference.append(value)\n",
    "\n",
    "pyplot.plot(difference)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now an augmented Dickey-Fuller (ADF) test is performed to test the stationarity of the data. The null hypothesis is that the data is not stationary, and the alternative is that the data is stationary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(difference)\n",
    "print(f\"ADF Statistic: {result[0]:f}\")\n",
    "print(f\"P-value: {result[1]:f} \" + (\"< 0.01 (significant)\" if result[1] < 0.01 else \"> 0.01 (insignificant)\"))\n",
    "print(\"Critical values:\")\n",
    "for key, value in result[4].items():\n",
    "    print(f\"\\t{key}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look for outliers by calculating Q1, Q3, IQR, and seeing which datapoints fall outside the bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate upper and lower bounds for detecting outliers\n",
    "q1 = np.quantile(difference, 0.25)\n",
    "q3 = np.quantile(difference, 0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "min_bound = q1 - 1.5 * iqr\n",
    "max_bound = q3 + 1.5 * iqr\n",
    "\n",
    "\n",
    "# look for anomalies in the data from the last month\n",
    "last_month = datetime.now() - pd.DateOffset(months=1)\n",
    "last_month = datetime(last_month.year, last_month.month, 1)  # round to first day of month\n",
    "\n",
    "anomalies = {\n",
    "    \"QUOTE_DATE\": [],\n",
    "    \"Net Closing Rate\": [],\n",
    "}\n",
    "historical_anomalies = {\n",
    "    \"QUOTE_DATE\": [],\n",
    "    \"Net Closing Rate\": [],\n",
    "}\n",
    "\n",
    "for i in range(len(df_new)):\n",
    "    value = difference[i]\n",
    "    date = df_new[\"QUOTE_DATE\"].iloc[i]\n",
    "    if (value < min_bound) or (value > max_bound):\n",
    "        # append original data rather than transformed data\n",
    "        if date >= last_month:\n",
    "            anomalies[\"QUOTE_DATE\"].append(df_new[\"QUOTE_DATE\"].iloc[i])\n",
    "            anomalies[\"Net Closing Rate\"].append(df_new[\"Net Closing Rate\"].iloc[i])\n",
    "        else:\n",
    "            historical_anomalies[\"QUOTE_DATE\"].append(df_new[\"QUOTE_DATE\"].iloc[i])\n",
    "            historical_anomalies[\"Net Closing Rate\"].append(df_new[\"Net Closing Rate\"].iloc[i])\n",
    "\n",
    "print(\"Recent anomalies (last month)\\n-----------------------------\")\n",
    "display(pd.DataFrame(anomalies))\n",
    "print(\"\\nHistorical anomalies\\n-----------------------------\")\n",
    "display(pd.DataFrame(historical_anomalies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can loop through all states to perform the process on the entire dataframe all at once. Note this only outputs recent outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "DATASET_PATH = os.environ.get(\"DATASET_PATH\")\n",
    "\n",
    "# main dataframe\n",
    "df_main = pd.read_excel(DATASET_PATH + \"Conversion by Day.xlsx\")\n",
    "\n",
    "# get a list of the categories for this dimension, e.g. ['ACT', 'NSW', ...] for POLICY: Risk State\n",
    "categories = df_main[df_main.columns[0]].tolist()\n",
    "categories = sorted(list(set(categories)))  # remove duplicate groupings and sort alphabetically\n",
    "\n",
    "response_col = int(input(\"Column number of the response variable: \"))\n",
    "response = df_main.columns[response_col]\n",
    "\n",
    "anomaly_dfs = []  # to store the integer locations of anomalies in the dataframe\n",
    "    \n",
    "for category in categories:\n",
    "    # filter out all other categories\n",
    "    df = df_main.loc[df_main.iloc[:, 0] == category]\n",
    "    \n",
    "    # fit polynomial to curve - first determine coefficients of polynomial\n",
    "    n = len(df[response])\n",
    "    x = [i % 365 for i in range(n)]\n",
    "    y = df[response].values\n",
    "    degree = 10\n",
    "    coefficients = np.polyfit(x, y, degree)\n",
    "    \n",
    "    # create the polynomial curve\n",
    "    polynomial = []\n",
    "    for i in range(n):\n",
    "        value = coefficients[-1]\n",
    "        for d in range(degree):\n",
    "            # calculate polynomial value at each point\n",
    "            value += x[i]**(degree-d) * coefficients[d]\n",
    "        polynomial.append(value)\n",
    "\n",
    "    # seasonality/trend adjustment - take the difference between the original and polynomial values\n",
    "    adjusted_response = []\n",
    "    for i in range(n):\n",
    "        new_value = y[i] - polynomial[i]\n",
    "        adjusted_response.append(new_value)\n",
    "    # insert adjusted response variable into the dataframe as a new column\n",
    "    df.insert(response_col+1, f\"Adjusted {response}\", adjusted_response, False)\n",
    "    \n",
    "    # calculate upper and lower bounds for detecting outliers\n",
    "    q1 = df[f\"Adjusted {response}\"].quantile(0.25)\n",
    "    q3 = df[f\"Adjusted {response}\"].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    min_bound, max_bound = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    \n",
    "    # look for anomalies in the data from the past & current month\n",
    "    last_month = datetime.now() - pd.DateOffset(months=2)\n",
    "    last_month = datetime(last_month.year, last_month.month, 1)  # round to first day of month\n",
    "    \n",
    "    anomalies = []    \n",
    "    for i in range(n):\n",
    "        value = df[f\"Adjusted {response}\"].iloc[i]\n",
    "        date = df[\"QUOTE_DATE\"].iloc[i]\n",
    "        if (not (min_bound <= value <= max_bound)) and date >= last_month:\n",
    "            anomalies.append(i)\n",
    "            \n",
    "    anomaly_dfs.append(df.iloc[anomalies, :])\n",
    "\n",
    "# filter out only the anomalies from the original dataframe\n",
    "df_outliers = pd.concat(anomaly_dfs)\n",
    "display(df_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
